\documentclass{article}

% PREAMBLE %
\usepackage{graphicx} % for importing images
\usepackage{xcolor} %for coloring text
\usepackage{amsmath,amssymb,bm}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}

%tikz libaries
\usetikzlibrary{calc,angles,quotes}
\usetikzlibrary{intersections} %for intersections between \paths

% CUSTOM COMMANDS %

% Bold vectors for Latin and Greek:
\newcommand{\vect}[1]{\bm{#1}}    % \vect{x}, \vect{\alpha}, \vect{\nabla}
\newcommand{\uvect}[1]{\hat{\bm{#1}}} % unit vectors: \uvect{n}


% METADATA %
\author{Thomas Dizon}
\title{CPU Graphics Engine}

% CONTENT %
\begin{document}

\maketitle

\begin{figure}[h]
	\centering
	\includegraphics[width=0.6\textwidth]{scene.png}
	\caption{}
\end{figure}

\newpage

\tableofcontents

\newpage

\section{Introduction}

\subsection{Motivation}
\begin{itemize}
\item As someone interested in developing 3D games and graphics, I was frustrated with how much I didn't understand when I used game engines like Unity and Godot. When I wanted to achieve a simple effect like adding grass, water or natural-looking terrain, I was overwhelmed with my own inability. Thus, I committed myself to building a 3D engine from scratch so I could allow these concepts that I didn't understand emerge naturally as byproducts as I worked towards the goal of rendering 3D objects. 
\item Now that I've more or less finished the project, it is A LOT easier now to imagine how to achieve some graphical effect like a grass or water shader. Since I understand how it works conceptually under the hood, the programming is a lot easier.
\item It's also a great precursor to understanding more in depth how the GPU works.
\end{itemize}

\subsection{What is a \textit{Graphics Engine}?}
\begin{itemize}
\item The 'rasterization' step in the graphics render pipline is a specific part which involves converting Primitives into Fragments
\item A primitive, in my case, is a Triangle and a Fragment is an (x,y) value on the screen with an additional z value to track its depth
\item In the real world, rasterization is done purely through specialized hardware on the GPU (which is why it is so fast)
\item To conceptually understand how it works, instead of building a GPU from scratch (hard), I'll use my good old CPU to do the rasterizing (still hard but easier)
	\item Just to clarify between similar terms. A "Software Rasterizer" refers to writing a CPU implementation of the Rasterization step in a "Software Renderer". A "Software Renderer" is a CPU implementaion of the Graphics Pipeline. A "Graphics Engine" is a CPU implementation of the graphics pipeline as well as Scene Management, Asset Management, Input handling, Updating the Scene etc. It falls short of being a fully fledged game engine but the scope is larger than a Software Renderer
\end{itemize}

\subsection{Why \textit{C}?}
\begin{itemize}
\item I first touched C during my Systems Programming course at University. It was extrememly difficult for me at the time but very benefiical for my programming skills. I felt that I haven't extracted all that I can from the language yet.
\item Also, I wanted to get as low level as possible for this project to ensure I had minimal dependencies. To truly understand the Graphics Pipeline, I wanted to build it truly (well, mostly) from scratch
\end{itemize}

\subsection{What does the project depend on?}
\begin{itemize}
\item Right now, it depends on the C standard library, std\_image.h (reference) for dealing with .png files and SDL2 (reference) for handling all the OS level stuff like inputs and writing to the screen. Though you could easily replace SDL with any other library which creates Windows for you like RayLib.
\end{itemize}

\section{The Graphics Engine}
\subsection{Diagram}
\subsection{Overview}
\begin{itemize}
\item{Preparing Assets for the Scene}
\item{Preparing the Scene}
\item{Updating the Scene}
\item{Primitive Assembly}
\item{Vertex Shader}
\item{Clipping \& Viewport}
\item{Rasterization}
\item{Fragment Shader}
\item{Output Merging \& Depth Test}
\end{itemize}

\section{3D Geometry in Memory}

\subsection{How do you represent a 3D object on a computer?}
\subsection{Vertices and Triangles}
\begin{itemize}
\item Using a Mesh
\end{itemize}
\subsection{3D Mesh}
\subsection{3D File types}

\section{Coordinate Spaces}
\subsection{What is a \textit{Coordinate Space}?}
\subsection{GameObjects \& Object Space}
\subsection{Scenes \& World Space}
\subsection{Cameras \& View Space}

\section{Transforming Vertices}
\subsection{Matrices as Transformations}

\subsection{Deriving the Model Matrix}
\subsubsection{Transforms}
\subsubsection{Scale Matrix}
\subsubsection{Rotation Matrix}
\subsubsection{Translation Matrix}
\subsubsection{Combining them together}

\subsection{Deriving the View Matrix}
\subsubsection{The Matrix Inverse}
\subsubsection{Inverse of the Model Matrix}

\subsection{Deriving the Projection Matrix}

The goal of this section is to come up with some matrix $\textbf{P}$ that transforms vertices from View Space into Clip Space. We wish to do it in such a way that Perspective is captured, and that vertices inside the View Frustum are mapped to Normalized Device Coordinates.

Normalized Device Coordinates (NDC) is given by all points (x,y,z) such that $x \in [-1,1]$, $y \in [-1,1]$ and $z \in [0,1]$ which matches the \textit{Vulkan} convention.

Mathematically, we want to find $P$ such that

\[
\mathbf{Pv_{view}} =
\begin{pmatrix}
m_{11} & m_{12} & m_{13} & m_{14} \\
m_{21} & m_{22} & m_{23} & m_{24} \\
m_{31} & m_{32} & m_{33} & m_{34} \\
m_{41} & m_{42} & m_{43} & m_{44}
\end{pmatrix}%
\begin{pmatrix}
x \\ y \\ z \\ 1
\end{pmatrix}
=
\begin{pmatrix}
	x_{ndc} \\ y_{ndc} \\ z_{ndc} \\ z_{view}
\end{pmatrix}

\]

\subsubsection{What is \textit{Perspective}?}
\begin{itemize}
	\item In this project, my goal is to create graphics that are visually realistic or at least somewhat consistent with our experiences in the real world. Thus, my definition of Perspective will be made with that in mind.
	\item Put simply, Perspective is the phenomenon of objects appearing smaller to a viewer as it moves further away from the viewer.
	\item The viewer perceives the world through projecting a 3D world onto a 2D 'viewing plane'
	\item It comes from that fact that we, as humans, perceive a 3D world through light striking a 2D surface, our retina after passing through a 'pinhole' which is our iris.
	\item Our eye accepts light from all objects in the surrounding area in a 'radial' fashion. As a result, distant objects appear smaller, while nearby objects appear larger.
	\item Mathematically, the apparent size of an object is inversely proportional to its distance from the observer.
\end{itemize}

\subsubsection{The View Frustum}
\begin{itemize}
	\item Since we are trying to create realistic graphics on a computer screen, we need to take that screen into account.
	\item We imagine that the computer screen is not a screen but instead a 'Window' into the virtual world we are creating. We can now place this Window into the Scene, in world space. The Width and Height of the window is proportional to the actual width and height of the Window running the program (Viewport)
	\item The distance between the viewer and the screen in World Space is given by the Field Of View paremeter which is an angular measurement.  
	\item So now the image is: We, the viewer, are the Camera in the Scene and the Computer Screen is some distance directly in front of us, almost as we are in real life.
	\item Now, in world space, we can extend the Computer Screen out into infinite and call it the 'near plane'	
	\item So that we don't blow up our computers by trying to render infinitely into the distance, we also define a 'Far Plane' based on the maximum distance from the Viewer we wish to see.
	\item Now, we can't see above, below, right or left of the window so we can trace a line from the Camera to each edge of the viewport and create The Top, Left, Right and Bottom planes from that.
	\item The objects inside of this volume are the objects visible to our Viewer.
	\item All vertices inside the view frustum will be mapped to points inside our Canonical View Volume
\end{itemize}

\subsubsection{Perspective Projection}

After applying the Model and View Matrix to each Vertex in the Scene, each Vertex should now be in View space (Coordinates expressed relative to the Camera being at the origin). We want to project each Vertex onto the Viewing Plane which is the same thing as the Near Plane. For now, we ignore the $z$ and $w$ values.

For each Vertex, imagine constructing a line from the Vertex to the Origin. This line's intersection on the Viewing plane will be the Vertex's projection. 

The parametric vector representing a line passing through points $A$ and $B$ is given by 

\[
	\textbf{r}(t) = \textbf{A} + t(\textbf{B} - \textbf{A}), t \in \mathbb{R}
\]

In our case, $A = (0,0,0)$ and $B$ = $v$. Thus,

\[
	\textbf{r}(t) = \textbf{v}t
\]

To calculate where it intersects the near plane, we solve the equation for $t$ after setting $r_z =n$, where $n$ how far the near plane is along the $z$ axis.

\[
	r_z = n \Rightarrow v_zt_{int.} = n \Rightarrow t_{int.} = \frac{n}{v_z}
\]

Then,
\[
	\textbf{r}(t_{int.}) = \textbf{v}(\frac{n}{v_z})
			     = (\frac{nv_x}{v_z}, \frac{nv_y}{v_z}, n)
\]

In other words, the projected $x$ and $y$ values of the vertex $\textbf{v}$ on the near plane will be ${nv_x}/{v_z}$ and ${nv_y}/{v_z}$ respectively. 

This scaling will capture the effect of perspective as can be seen in Figure \ref{fig:2d-frustum}. Despite the two Cobblemon having the same height in View / World Space, their projected heights onto the viewing / near plane (measured from y = 0 to the projection point) is such that the further cobblemon is smaller than the closer cobblemon.

Now, we just need to make sure that points inside the view frustum are mapped to normalized device coordinates. That is, points that intersect the top plane are mapped to y = 1, bottom y = -1, left x = -1, right x = 1.

To do that, let's now imagine that we are the camera and are looking at the view port.
\begin{figure}[h!]
\centering
\begin{tikzpicture}
	\def\Xmax{3};
	\def\Ymax{3};

	% Viewport Box
	\def\botLeftX{-2.5}
	\def\botLeftY{-1.5}
	\def\topRightX{2.5}
	\def\topRightY{1.5}

	\filldraw[fill=red!20, draw=black]
    		(\botLeftX,\botLeftY) rectangle (\topRightX,\topRightY);

	% axes
	\draw[->] (-\Xmax,0) -- (\Xmax,0) node[right] {$x$};
	\draw[->] (0,-\Ymax) -- (0,\Ymax) node[above] {$y$};

	\def\smallGap{0.05}

	% r label
	\draw[decorate, decoration={brace, amplitude=6pt}, blue]
        	(\smallGap,\topRightY + \smallGap) -- (\topRightX - \smallGap,\topRightY + \smallGap)
        	node[midway, above=7pt, blue] {$r$};

	% t label
	\draw[decorate, decoration={brace, amplitude=6pt, raise=2pt}, red]
        	(\topRightX, \topRightY - \smallGap) -- (\topRightX,0+\smallGap)
        	node[midway, right=7pt, red] {$t$};

	%charmander graphic
	\node at (-0.6,0.35) {\includegraphics[height=1.8cm]{charmander_front_alpha.png}};
	\node at (0.4,0.36) {\includegraphics[height=1cm]{charmander_front_alpha.png}};

	\end{tikzpicture}
\end{figure}

So we can now determine the first 2 rows of the matrix. To scale the $x$ and $y$ components by $n/v_z$, we need to set $m11$ and $m22$ to be $n$ and everythign else in rows 1 and 2 to be 0.

\[
\mathbf{Pv_{view}} =
\begin{pmatrix}
$n/z$ & 0 & 0 & 0 \\
0 & $n/z$ & 0 & 0 \\
m_{31} & m_{32} & m_{33} & m_{34} \\
m_{41} & m_{42} & m_{43} & m_{44}
\end{pmatrix}%
\begin{pmatrix}
x \\ y \\ z \\ 1
\end{pmatrix}
=
\begin{pmatrix}
	x_{ndc} \\ y_{ndc} \\ z_{ndc} \\ z_{view}
\end{pmatrix}

\]

From the maths, we can immediately see that the apprent size of the image on the near / viewing plane is inversely proportional to its distance from the viewer, and directly proportional to the distance from the plane to the viewer.
\begin{figure}[h!]

	\definecolor{topplane}{HTML}{2E8B57}   % Sea Green (clear, calm)
	\definecolor{bottomplane}{HTML}{A0522D} % Sienna (warm earthy brown)
	\definecolor{nearplane}{HTML}{1E90FF}   % Dodger Blue (bright but not neon)
	\definecolor{farplane}{HTML}{DC143C}    % Crimson Red (vivid but deep)

	\centering
	\textbf{View Space}\\[0.5em]%
	\begin{tikzpicture}
		% parameters
		\def\t{0.4} % tan(fov/2)
		\def\n{2.0}       % near
		\def\f{6.5}       % far
		\def\Zmax{7}      % drawing extent
		\def\Ymax{3}

		% axes
		\draw[->] (-0.5,0) -- (\Zmax+0.5,0) node[right] {$z$};
		\draw[->] (0,-\Ymax) -- (0,\Ymax)       node[above] {$y$};

		% top/bottom (black)
		\draw[] plot[domain=0:\Zmax] (\x,  { \t*\x});
		\draw[] plot[domain=0:\Zmax] (\x, {- \t*\x});

		%top (colored)
		\draw[topplane] plot[domain=\n:\f] (\x,  { \t*\x});

		%bottom (colored)
		\draw[bottomplane] plot[domain=\n:\f] (\x,  { -\t*\x});

		% near/far from z = n, z = f  (verticals)
		% use the y-extent implied by the frustum at those z
		\draw[thick,nearplane, name path=near] plot[domain={- \t*\n}:{ \t*\n}] ({\n}, \x);
		\draw[thick,farplane, name path=far ] plot[domain={- \t*\f}:{ \t*\f}] ({\f}, \x);
		
		%extend near and far planes to inifinite with colored dotted lines
		\draw[dashed,nearplane, name path=near] plot[domain={-\Ymax}:{ \Ymax}] ({\n}, \x);
		\draw[dashed, farplane, name path=far ] plot[domain={- \Ymax}:{ \Ymax}] ({\f}, \x);

		% near / far labels
		\draw (\n, 0) node[below right] {$n$};
		\draw (\f, 0) node[below right] {$f$};

		% sample vertex
		\def\vx{3.1}
		\def\vy{0.9}
		\draw[fill=black] (\vx,\vy) circle (1pt) node[above right] {$v_1$};

		\def\ux{5.6}
		\def\uy{0.9}
		\draw[fill=black] (\ux,\uy) circle (1pt) node[above right] {$v_2$};

		%label the origin as C, the Camera
		\draw circle (0,0) node[below left] {$C$};
		
		% line from origin to vertex
		\draw[dashed, name path=vline] (0,0) -- (\vx,\vy);
		\draw[dashed, name path=uline] (0,0) -- (\ux,\uy);

		%label intersection between near plane and vline
		\path[name intersections={of=vline and near, by=I}];
		\path[name intersections={of=uline and near, by=IU}];
		\fill (I) circle (1pt) node[above right];
		\fill (IU) circle (1pt) node[below right];
		
		%charmander graphic
		\node at (3.3,0.45) {\includegraphics[height=1.2cm]{charmander_left_alpha.png}};
		\node at (5.8,0.45) {\includegraphics[height=1.2cm]{charmander_left_alpha.png}};
		
		%projection labels
		\node (A) at (1,1) {$v_2'$};
		\node (B) at (1,2) {$v_1'$};

		% arrows from labels to points
		\draw[->, bend right] (A) to (IU);
		\draw[->, bend right] (B) to (I);
	\end{tikzpicture}

	\caption{2D slice of the view frustum along the $yz$ plane depicting the \textcolor{topplane}{top}, \textcolor{bottomplane}{bottom}, \textcolor{nearplane}{near} and \textcolor{farplane}{far planes}. The vertex $v$ is projected to the point $v'$ on the near plane by calculating the intersection between a line drawn from the origin to $v$ and the near plane. The Camera / Viewer, labelled {$C$} is at the origin, thus this Coordinate Space is View Space.}
	\label{fig:2d-frustum}

\end{figure}

\begin{figure}[h!]

	\definecolor{topplane}{HTML}{2E8B57}   % Sea Green (clear, calm)
	\definecolor{bottomplane}{HTML}{A0522D} % Sienna (warm earthy brown)
	\definecolor{nearplane}{HTML}{1E90FF}   % Dodger Blue (bright but not neon)
	\definecolor{farplane}{HTML}{DC143C}    % Crimson Red (vivid but deep)

	\centering
	\textbf{View Space}\\[0.5em]%
	\begin{tikzpicture}
		% parameters
		\def\t{0.4} % tan(fov/2)
		\def\n{2.0}       % near
		\def\f{5.5}       % far
		\def\Zmax{7}      % drawing extent
		\def\Ymax{3}

		% axes
		\draw[->] (-0.5,0) -- (\Zmax+0.5,0) node[right] {$z$};
		\draw[->] (0,-\Ymax) -- (0,\Ymax)       node[above] {$x$};

		% top/bottom (black)
		\draw[] plot[domain=0:\Zmax] (\x,  { \t*\x});
		\draw[] plot[domain=0:\Zmax] (\x, {- \t*\x});

		%top (colored)
		\draw[topplane] plot[domain=\n:\f] (\x,  { \t*\x});

		%bottom (colored)
		\draw[bottomplane] plot[domain=\n:\f] (\x,  { -\t*\x});

		% near/far from z = n, z = f  (verticals)
		% use the y-extent implied by the frustum at those z
		\draw[thick,nearplane, name path=near] plot[domain={- \t*\n}:{ \t*\n}] ({\n}, \x);
		\draw[thick,farplane, name path=far ] plot[domain={- \t*\f}:{ \t*\f}] ({\f}, \x);
		
		%extend near and far planes to inifinite with colored dotted lines
		\draw[dashed,nearplane, name path=near] plot[domain={-\Ymax}:{ \Ymax}] ({\n}, \x);
		\draw[dashed, farplane, name path=far ] plot[domain={- \Ymax}:{ \Ymax}] ({\f}, \x);

		% near / far labels
		\draw (\n, 0) node[below right] {$n$};
		\draw (\f, 0) node[below right] {$f$};

		% sample vertex
		\def\vx{3}
		\def\vy{0.9}
		\draw[fill=black] (\vx,\vy) circle (1pt) node[above right] {$v_1$};

		\def\ux{4.3}
		\def\uy{-0.9}
		\draw[fill=black] (\ux,\uy) circle (1pt) node[below right] {$v_2$};

		%label the origin as C, the Camera
		\draw circle (0,0) node[below left] {$C$};
		
		% line from origin to vertex
		\draw[dashed, name path=vline] (0,0) -- (\vx,\vy);
		\draw[dashed, name path=uline] (0,0) -- (\ux,\uy);

		%label intersection between near plane and vline
		\path[name intersections={of=vline and near, by=I}];
		\path[name intersections={of=uline and near, by=IU}];
		\fill (I) circle (1pt) node[above right];
		\fill (IU) circle (1pt) node[below right];
		
		%charmander graphic
		\node at (3.2,0.4) {\includegraphics[height=1.5cm]{charmander_top_alpha.png}};
		\node at (4.5,-0.4) {\includegraphics[height=1.5cm]{charmander_top_alpha.png}};

	\end{tikzpicture}

	\label{fig:2d-frustum-xz}

\end{figure}


This transformation on the $x$ and $y$ coordinates is actually enough to capture the effect of perspective. However, since we essential squish everything in the View Volume onto a 2D plane, unless we do something about it, we lose out on Depth information.

Depth is important to us for two reasons:
\begin{enumerate}
	\item Relative ordering of objects in the Scene for depth test
	\item View Space depth for Shader calculations / Alpha blending
\end{enumerate}

To solve 1, we come up with some transformation of the z value to map it to our Canonical View Volume which, in my case, is 0 - 1. We require that vertices on the near plane are mapped to 0 and vertices on the far plane are mapped to 1.

\[
\mathbf{Pv} =
\begin{pmatrix}
m_{11} & m_{12} & m_{13} & m_{14} \\
m_{21} & m_{22} & m_{23} & m_{24} \\
m_{31} & m_{32} & m_{33} & m_{34} \\
m_{41} & m_{42} & m_{43} & m_{44}
\end{pmatrix}%
\begin{pmatrix}
x \\ y \\ z \\ w
\end{pmatrix}

\]


\subsection{Deriving The Viewport Matrix}
\subsection{The Vertex Shader}
\subsection{Clipping \& The Sutherland Hodgman Algorithm}

\section{Drawing to the screen}
\subsection{What is \textit{Rasterization}?}
\subsection{Interpolation}
\subsection{Rasterizing Triangles}
\subsection{What is a \textit{Fragment?}}
\subsection{The Fragment Shader}
\subsection{Depth Testing}
\subsection{The Framebuffer and Z-Buffer}

\section{Shading}

\subsection{Shaders}
\subsection{Materials}
\begin{itemize}
	\item A Material
	\item It contains ...
\end{itemize}

\subsection{Textures}
\subsection{Unlit Shader}
\subsection{Lit Shader}
\subsection{Phong Shader}
\subsection{Toon Shader}
\subsection{Shadows}
\subsection{Ambient Occlusion}

\section{Appendix}
\subsection{Quaternions}
\subsection{Barycentric Coordinates}
\section{Deprecated}
\subsection{Math Concepts}
\subsubsection{Vectors}
\begin{itemize}
\item In this document, we will use typical Vector operations and notation including but not limited to the following
\item A vector is $\textbf{v}$ is a collection of real numbers denoted by 
\item The \textit{dot product} is defined by
\item The \textit{cross product} is defined by
\item A unit vector is denoted by the hat
\end{itemize}

\subsubsection{Planes}
\begin{itemize}
	\item A plane is defined by \textbf{**TODO**}
\end{itemize}
\subsubsection{Matrices}

\begin{itemize}
	\item To understand Graphics Engines, you must become somewhat familiar with the operation of matrices. In particular: Matrix Multiplication, Inverse Matrices, Matrices as Linear Transformations and probably more. I provide a very scarce review below.
	\item Matrix multiplication is done like so:
	\item Matrix Inverse is calculated like so:
	\item For an affine, orthonormal matrix, the inverse can be calculated like this ( + reference)
\end{itemize}
\subsubsection{Quaternions}
\begin{itemize}
	\item To represents rotations in 3D space, I use Quaternions. While you can use a composition of 3x3 Euler Matrices, they are slower, hard to interpolate and are at risk of Gimbal Lock (+ Reference).
	\item A Quaternion is a kind of 4D complex number $q = q_0 + q$ where $q_0$ is a scalar and
$q$ is an R3 vector where each component has unit vectors $i, j, k$.
	\item The unit vectors $i,j,k$ adhere to the following multiplication rules. \textbf{**TODO**}
	\item Whenever you are interested in rotating an object in 3D space, you need to specify 2 things: An axis and an angle. These are encoded in the Unit Quaternion in the following way: \textbf{**TODO**}
	\item In the space of Unit Quaternions, if you operate a Unit Quaternion on a Vector, it results in a rotation of some degrees about some axis.
\end{itemize}
\subsubsection{Coordinate Spaces}
\begin{itemize}
	\item Cartesian
	\item Projective
	\item Barycentric
	\item Spherical, Cylindrical
\end{itemize}
\subsubsection{Transformations}
\begin{itemize}
	\item Model, View, Projection
\end{itemize}
\subsubsection{Deriving the Model Matrix}
\subsubsection{Deriving the View Matrix}
\subsubsection{Deriving the Projection Matrix}

The Projection Matrix is responsible for converting vertices from View space into Clip space. It aims to morph points that lie inside or on the View frustum into the Canonical View Volume in such a way that \textit{perspective} is introduced.  

\par\medskip
Perspective is described simply by the idea that things that are far away seem small and things that are close seem big.

\par\medskip
We break the problem  up into 2 parts:
\begin{enumerate}
	\item Calculating the transformation for $x$ and $y$
	\item Calculating the transformation for $z$
\end{enumerate}

For the first part, consider the setup in Figure ?. In this 2D slice, the viewing volume is given by the near and far planes and the top and bottom planes. What we wish to do is to take some point $v$, and project it onto the near plane. 

To do this, we draw a line from the point to the origin. Consider the point at which this origin ray intersects the near plane. Let's call this point $x$. 


\subsubsection{Deriving the Viewport Matrix}
\subsection{Algorithms}
\subsubsection{Rasterization}
\subsubsection{Improved Rasterization}
\begin{itemize}
	\item (First Approach) Takes a Primitive (Triangle made of Vertices) after is has been transformed by MVP and VP. It computes Bounding Box and using BaryCentric Coordinates with respect to the Triangle vertex positions decides which pixels to remove based on whether they are inside or outside of the triangle \textbf{**FIGURE**}
	\item (Optimized Approach) Iterative Edge Functions \textbf{**TODO**}
\end{itemize}

\subsubsection{Clipping}
\begin{itemize}
	\item After the Vertex Shader is applied, triangle vertices should be in \textit{Clip Space}, which is a \textit{homogeneous vector space} in $R^4$ where $v = (x,y,z,w)$ maps to $u = (x/w, y/w, z/w)$ in $R^3$
	\item The goal of this algorithm is to \textit{clip} the triangle against the \textit{View Frustum}, which in homoegenous space is a volume bounded by 6 4D planes.
	\item We start by deriving an expression for each planes, represented by a normal vector $n \in \mathbb{R}^4$ and some point on the vector $p \in \mathbb{R}^4$
	\item The projection matrix maps each of the 6 $\mathbb{R}^3$ planes that define the view frustum. \textbf{**TODO**} Show that the 6 view frustum planes map to the planes used in 4 space

\item \textbf{**TODO**} Write some pseudocode, include a diagram

\end{itemize}
\section{Conclusion \& Future Work}

\subsection{What I learnt}

\subsection{Limitations}

\subsection{A future implementation in C++}


\section{References}

\end{document}

