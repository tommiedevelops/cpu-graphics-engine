\documentclass{article}

% PREAMBLE %
\usepackage{graphicx} % for importing images
\usepackage{xcolor} %for coloring text
\usepackage{subcaption} %for subfigures
\usepackage{amsmath,amssymb,bm}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}

%tikz libaries
\usetikzlibrary{calc,angles,quotes}
\usetikzlibrary{intersections} %for intersections between \paths

% CUSTOM COMMANDS %

% Bold vectors for Latin and Greek:
\newcommand{\vect}[1]{\bm{#1}}    % \vect{x}, \vect{\alpha}, \vect{\nabla}
\newcommand{\uvect}[1]{\hat{\bm{#1}}} % unit vectors: \uvect{n}

% METADATA %
\author{Thomas Dizon}
\title{CPU Graphics Engine}

% CONTENT %
\begin{document}

\maketitle

\begin{figure}[h]
	\centering
	\includegraphics[width=0.6\textwidth]{scene.png}
	\caption{}
\end{figure}

\newpage

\tableofcontents

\newpage

\section{Introduction}

\subsection{Motivation}
\begin{itemize}
\item As someone interested in developing 3D games and graphics, I was frustrated with how much I didn't understand when I used game engines like Unity and Godot. When I wanted to achieve a simple effect like adding grass, water or natural-looking terrain, I was overwhelmed with my own inability. Thus, I committed myself to building a 3D engine from scratch so I could allow these concepts that I didn't understand emerge naturally as byproducts as I worked towards the goal of rendering 3D objects. 
\item Now that I've more or less finished the project, it is A LOT easier now to imagine how to achieve some graphical effect like a grass or water shader. Since I understand how it works conceptually under the hood, the programming is a lot easier.
\item It's also a great precursor to understanding more in depth how the GPU works.
\end{itemize}

\subsection{What is a \textit{Graphics Engine}?}
\begin{itemize}
\item The rasterization step in the graphics render pipline is a specific part which involves converting Primitives into Fragments
\item A primitive, in my case, is a Triangle and a Fragment is an (x,y) value on the screen with an additional z value to track its depth
\item In the real world, rasterization is done purely through specialized hardware on the GPU (which is why it is so fast)
\item To conceptually understand how it works, instead of building a GPU from scratch (hard), I'll use my good old CPU to do the rasterizing (still hard but easier)
\item Just to clarify between similar terms. A ``Software Rasterizer'' refers to writing a CPU implementation of the Rasterization step in a ``Software Renderer''. A ``Software Renderer'' is a CPU implementaion of the Graphics Pipeline. A ``Graphics Engine'' is a CPU implementation of the graphics pipeline as well as Scene Management, Asset Management, Input handling, Updating the Scene etc. It falls short of being a fully fledged game engine but the scope is larger than a Software Renderer
\end{itemize}

\subsection{Why \textit{C}?}
\begin{itemize}
\item I first touched C during my Systems Programming course at University. It was extrememly difficult for me at the time but very benefiical for my programming skills. I felt that I haven't extracted all that I can from the language yet.
\item Also, I wanted to get as low level as possible for this project to ensure I had minimal dependencies. To truly understand the Graphics Pipeline, I wanted to build it truly (well, mostly) from scratch
\end{itemize}

\subsection{What does the project depend on?}
\begin{itemize}
\item Right now, it depends on the C standard library, std\_image.h (reference) for dealing with.png files and SDL2 (reference) for handling all the OS level stuff like inputs and writing to the screen. Though you could easily replace SDL with any other library which creates Windows for you like RayLib.
\end{itemize}

\section{The Graphics Engine}
\subsection{Diagram}
\subsection{Overview}
\begin{itemize}
\item{Preparing Assets for the Scene}
\item{Preparing the Scene}
\item{Updating the Scene}
\item{Primitive Assembly}
\item{Vertex Shader}
\item{Clipping \& Viewport}
\item{Rasterization}
\item{Fragment Shader}
\item{Output Merging \& Depth Test}
\end{itemize}

\section{3D Geometry in Memory}

\subsection{How do you represent a 3D object on a computer?}
\subsection{Vertices and Triangles}
\begin{itemize}
\item Using a Mesh
\end{itemize}
\subsection{3D Mesh}
\subsection{3D File types}

\section{Coordinate Spaces}
\subsection{What is a \textit{Coordinate Space}?}
\subsection{GameObjects \& Object Space}
\subsection{Scenes \& World Space}
\subsection{Cameras \& View Space}

\section{Transforming Vertices}
\subsection{Matrices as Transformations}

\subsection{Deriving the Model Matrix}
\subsubsection{Transforms}
\subsubsection{Scale Matrix}
\subsubsection{Rotation Matrix}
\subsubsection{Translation Matrix}
\subsubsection{Combining them together}

\subsection{Deriving the View Matrix}
\subsubsection{The Matrix Inverse}
\subsubsection{Inverse of the Model Matrix}

\subsection{The Vertex Shader}
\subsection{Perspective Projection}
\begin{itemize}
\item In a sentence, the goal of the Perspective Projection is to map the View Space `View Frustum' to `Canonical View Volume' in such a way that perspective is simulated.

\item The Canonical View Volume is all points (x,y,z) such that $x \in [-1,1]$, $y \in [-1,1]$ and $z \in [0,1]$ which matches the \textit{Vulkan} convention and a format understood by our rasterizer.

\item Perspective Projection is broken up into two steps:
\begin{enumerate}
\item Projection Matrix
\item Perspective Divide
\end{enumerate}

\item The \textit{Projection Matrix} transforms a vertex from View Space into Clip Space and the \textit{Perspective Divide}, which is ultimately responsible for simulating perspective, is given by the following operation: 
\[
	\begin{pmatrix}
		x\\
		y\\
		z\\
		w
	\end{pmatrix}
	\rightarrow
	\begin{pmatrix}
		x/w\\
		y/w\\
		z/w\\
		1
	\end{pmatrix}
\]

\item If you are confused, please keep reading! I go into more detail here.
\end{itemize}
\subsubsection{What is \textit{Perspective}?}
\begin{itemize}
	\item In this project, my goal is to create graphics that are visually realistic or at least somewhat consistent with our experiences in the real world. Thus, my definition of perspective will be made with that in mind.
	\item We start by assuming the viewer is `point like'. We, as humans, perceive the world through our eyes which are `point-like', in contrast to something like a Photosensor which perceives the world through a rectangular array of sensors.
	\item Put simply, Perspective is the phenomenon of objects appearing smaller to a point-like viewer as it moves further away from the viewer.
	\item In other words, the apparent size of an object to a viewer is inversely proportional to the object's distance to the viewer. This is a direct consequence of basic trigonometry.
\end{itemize}

\subsubsection{The View Frustum}
\begin{itemize}
	\item In this section, we motivate the definition of the \textit{View Frustum} and define what it is.

	\item To begin, I want you to close one eye and hold your index finger in front of it, close enough for it to appear blurry. Then, gradually move your index finger further away until it comes into focus. We define the distance between your eyeball and finger to be $n$, the \textit{near plane} distance.
	
	\item In our renderer, we choose not to render objects between the viewer and the near plane. 

	\item Pause for a moment. Take your right hand and point straight ahead with your index finger. Slowly move your arm as high as you can until the tip of your index finger is just invisible. Now do the same with your left arm. The angle between your arms is your Vertical Field of View (FOV) or $\theta_y$. You can easily repeat the exercise going left and right.

	\item This angle essential defines the edges of your vision. So it will be an important quantity for us in trying to recreate a realistic viewer.
	\item Since we are trying to create realistic graphics on a computer screen, we need to take that screen into account. Thus the last quantity that will be important to us is the \textit{aspect ratio}, $a$, which is the ratio between the width and height of the window you're using to render the virtual world.

	\item We also don't want to render infinitely into the distance because of the limited memory on our computers, so we also define $f$ the distance of the \textit{far plane} from the Camera along the z axis.

	\item In summary, the set of objects we care about rendering are those found within the volume in Figure \ref{fig:view-frustum}.
\end{itemize}

\begin{figure}[h!]
\centering
	\textbf{View Space}\\[0.5em]%
	\resizebox{0.6\textwidth}{!}{%
		\input{viewfrustum.tikz} % TODO: label n and f on the diagram
	}
	\caption{The View Frustum in View Space}\label{fig:view-frustum}
\end{figure}

\subsubsection{Deriving the Projection Matrix}
\begin{itemize}
	\item In this section we derive the Projection Matrix which maps the View Frustum to Homogeneous Clip Space. %TODO: reference the place where I exlpain homogeneous clip space
	\item We break it up into four steps
	\begin{enumerate}
		\item Scale $x$ and $y$ components such that perspective is captured.
		\item Scale $x$ and $y$ components again to $[-1,1]$ range
		\item Map $z$ to $[0,1]$ range such that relative depth is preserved
		\item Store original view space depth in $w$ variable
	\end{enumerate}

\end{itemize}
\textbf{1. Scale $x$ and $y$ such that perspective is captured}
\begin{itemize}
	\item To capture perspective, we project each vertex $v$ on the near plane via a line that passes through the origin and $v$.
	\item To project a vertex $\textbf{v}$ onto the near plane, we draw a line from the origin to that point and mark where it intersects the near plane.
	\item The parametric vector representing a line passing through points $A$ and $B$ is given by 
\[
	\textbf{r}(t) = \textbf{A} + t(\textbf{B} - \textbf{A}), t \in \mathbb{R}
\]

		In our case, $\textbf{A} = (0,0,0)$ and $\textbf{B}$ = $\textbf{v}$. Thus,

\[
	\textbf{r}(t) = \textbf{v}t
\]

We know that the $z$-component of the intersection point is going to be $n$.
\[
	\textbf{r}(t_i) = (v_{xt_i}, v_{yt_i}, v_{zt_i}) \\
		         = (v_{xt_i}, v_{yt_i}, n)
\]

Equating the $z$-components: 
		\[
			t_i = n/v_z
		\]
Thus,
\[
	\textbf{r}(t_{i}) = \left(\frac{nv_x}{v_z}, \frac{nv_y}{v_z}, n\right)
\]

\item In other words, the projected $x$ and $y$ values of the vertex $\textbf{v}$ on the near plane will be ${nv_x}/{v_z}$ and ${nv_y}/{v_z}$ respectively. 

\begin{figure}[h!]
	\centering%
	\textbf{View Space}\\[0.5em]% fix left diagram, circle?
	\begin{subfigure}{0.45\textwidth}
	\resizebox{\textwidth}{!}{%
		\input{frustum-side.tikz}
	}\label{fig:2d-frustum-yz}
	\end{subfigure}%
\hfill
	\begin{subfigure}{0.45\textwidth}
	\resizebox{\textwidth}{!}{%
		\input{frustum-top.tikz}
	}\label{fig:2d-frustum-xz}
	\end{subfigure}

\caption{Side by side graps of the x-z slice and y-z slice of the view frustum showing the how the projected image is calculated on the near plane}
\end{figure}

\end{itemize}
\textbf{2. Scale $x$ and $y$ to $[-1,1]$ range}
\begin{itemize}
	\item Now, we just need to make sure that points inside the view frustum are mapped to normalized device coordinates. That is, points that intersect the top plane are mapped to y = 1, bottom y = -1, left x = -1, right x = 1.

	\item To do this, let the distance from the z axis to the top of the viewport be r and the distance from the z axis to right side of the viewport be r.

	\item To match the dimensions of our window, we define the aspect ratioo $a$ to be $a = r/t$

	\item We can calculate r by considering FIGURE X. $\tan(\frac{\theta_u}{2}) = \frac{r}{n}$ so then $r = ntan(\frac{\theta_y}{2})$. 

	\item Then since $a = r/t$, $t = r/a$ which means $t = \frac{ntan(\frac{\theta_y}{2})}{a}$

	\item Now, if we scale the y component of all vertices on the near plane by $1/t$, this means that vertices in the range $[-r,r]$ will map to $[-1,1]$ and if we scale all the x components by $1/r$ all of the Vertices' x components will be in the range $[-1,1]$ which is exa tly what we need.
\begin{figure}[h!]
	\centering
	\textbf{View Space}\\[0.5em]%
	\resizebox{0.5\textwidth}{!}{%
		\input{frustum-front.tikz}
	}
	\caption{The view frustum from the perspective of the Camera}\label{fig:frustum-front}
\end{figure}

	
\item We now have what we need to figure out the firs two rows of the projection matrix. We need to scale the $x$ component by \textbf{TODO} and the $y$ component by \textbf{TODO} which can be done with the following matrix:
\[
\mathbf{Pv} =
\begin{pmatrix}
m_{11} & m_{12} & m_{13} & m_{14} \\
m_{21} & m_{22} & m_{23} & m_{24} \\
m_{31} & m_{32} & m_{33} & m_{34} \\
m_{41} & m_{42} & m_{43} & m_{44}
\end{pmatrix}%
\begin{pmatrix}
x \\ y \\ z \\ 1
\end{pmatrix}
=
\begin{pmatrix}
x\\y\\z\\1
\end{pmatrix}
\]

\end{itemize}
\textbf{3. Scale $z$ to $[0,1]$ range}
\begin{itemize}
	\item In order to determine the matrix elements that will transform the input $v_z$ into the desired $[0,1]$ range, we work backwards by considering what elements would be needed to map a point on the near plane to $z = 0$ and a point on the far plane to $z = 1$
	\item  We would need
\[
\begin{pmatrix}
m_{11} & m_{12} & m_{13} & m_{14} \\
m_{21} & m_{22} & m_{23} & m_{24} \\
m_{31} & m_{32} & m_{33} & m_{34} \\
m_{41} & m_{42} & m_{43} & m_{44}
\end{pmatrix}%
\begin{pmatrix}
x \\ y \\ n \\ 1
\end{pmatrix}
=
\begin{pmatrix}
x\\y\\0\\1
\end{pmatrix}
\]

\[
\begin{pmatrix}
m_{11} & m_{12} & m_{13} & m_{14} \\
m_{21} & m_{22} & m_{23} & m_{24} \\
m_{31} & m_{32} & m_{33} & m_{34} \\
m_{41} & m_{42} & m_{43} & m_{44}
\end{pmatrix}%
\begin{pmatrix}
x \\ y \\ f \\ 1
\end{pmatrix}
=
\begin{pmatrix}
x\\y\\1\\1
\end{pmatrix}
\]

\item We would need $m_{33}$ and $m_{34}$ to be \textbf{TODO} and \textbf{TODO} respectively

\item How we do this mapping doesn't actually matter that much, as long as relative ordering is preserved. 
\end{itemize}
\textbf{4. Store $w$ value}
\begin{itemize}
	\item Simply set $m_{43}$ to be 1
	\item Talk about homogeneous coordinates
\end{itemize}
\textbf{The Final Matrix}
\begin{itemize}
	\item Combining all the steps together, the final matrix is given by:

\[
	\textbf{P} = 	
\begin{pmatrix}
m_{11} & m_{12} & m_{13} & m_{14} \\
m_{21} & m_{22} & m_{23} & m_{24} \\
m_{31} & m_{32} & m_{33} & m_{34} \\
m_{41} & m_{42} & m_{43} & m_{44}
\end{pmatrix}%
\begin{pmatrix}
x \\ y \\ z \\ 1
\end{pmatrix}
=
\begin{pmatrix}
x\\y\\z\\w
\end{pmatrix}
\]
\end{itemize}

\subsubsection{Perspective Divide}
\begin{itemize}
	\item Once we have applied the perspective 
\end{itemize}
\subsection{Deriving The Viewport Matrix}
\subsection{Clipping \& The Sutherland Hodgman Algorithm}

\section{Drawing to the screen}
\subsection{What is \textit{Rasterization}?}
Hello
\subsection{Interpolation}
\subsection{Rasterizing Triangles}
\subsection{What is a \textit{Fragment?}}
\subsection{The Fragment Shader}
\subsection{Depth Testing}
\subsection{The Framebuffer and Z-Buffer}

\section{Shading}

\subsection{Shaders}
\subsection{Materials}
\begin{itemize}
	\item A Material
	\item It contains\ldots
\end{itemize}

\subsection{Textures}
\subsection{Unlit Shader}
\subsection{Lit Shader}
\subsection{Phong Shader}
\subsection{Toon Shader}
\subsection{Shadows}
\subsection{Ambient Occlusion}

\section{Appendix}
\subsection{Quaternions}
\subsection{Barycentric Coordinates}

\end{document}

